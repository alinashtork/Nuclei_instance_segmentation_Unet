# -*- coding: utf-8 -*-
"""Cell_nucleus_segmentation_Unet

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jG7cQA13eLlYpONBEgUv2aupiZtkHTcc

MÃ¼ller, D., Kramer, F. MIScnn: a framework for medical image segmentation with convolutional neural networks and deep learning. BMC Med Imaging 21, 12 (2021).
DOI: https://doi.org/10.1186/s12880-020-00543-7
"""

from google.colab import drive
drive.mount('/content/gdrive/')

import numpy as np
from google.colab.patches import cv2_imshow
import os
import cv2
import tensorflow as tf

names = os.listdir('/content/gdrive/MyDrive/miscnn_data/data_new2')
names.sort()
len(names)

path = '/content/gdrive/MyDrive/nucleus_pics_train'

# Here I make folders to save new masks there:

if not os.path.exists('/content/miscnn_data'): os.mkdir('/content/miscnn_data')
if not os.path.exists('/content/miscnn_data/data_new2'): os.mkdir('/content/miscnn_data/data_new2')
if not os.path.exists('/content/miscnn_data/contours'): os.mkdir('/content/miscnn_data/contours')

# Select files that are not uploaded yet
all_files = os.listdir(path)
files_to_upload = [x for x in all_files if x not in names]

# Upload files
for folder in files_to_upload:
  os.mkdir('/content/gdrive/MyDrive/miscnn_data/contours/' + folder)
  os.mkdir('/content/gdrive/MyDrive/miscnn_data/data_new2/' + folder)

  img = path + '/' + folder + '/images'
  image = cv2.imread(img + '/' + os.listdir(img)[0],  cv2.IMREAD_GRAYSCALE)
  print(os.listdir(img)[0])
  cv2_imshow(image)
# Upload images
  cv2.imwrite('/content/gdrive/MyDrive/miscnn_data/contours/' + folder + '/imaging.png', image)
  cv2.imwrite('/content/gdrive/MyDrive/miscnn_data/data_new2/' + folder + '/imaging.png', image)
  masks = path + '/' + folder + '/masks'
# make contours and masks with contours
  n = image.shape[0]
  m = image.shape[1]
  contours = np.ones([n, m])*255
  final_mask = np.zeros([n, m])

  for mask_name in os.listdir(masks):
    mask = cv2.imread(masks + '/' + mask_name, cv2.IMREAD_GRAYSCALE)
    final_mask += mask
    cnts, hier = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)
    for cnt in cnts[0]:
      contours[cnt[0][1], cnt[0][0]] = 0
    final_mask *= contours
# Save masks with contours and contours
  cv2_imshow(final_mask)
  cv2_imshow(contours)
  cv2.imwrite('/content/gdrive/MyDrive/miscnn_data/data_new2/' + folder + '/segmentation.png', final_mask)
  cv2.imwrite('/content/gdrive/MyDrive/miscnn_data/contours/' + folder + '/segmentation.png', contours)

!git clone https://github.com/alinashtork/MIScnn-for-nuclei-segmentation

!cd MIScnn

!python setup.py install

# Commented out IPython magic to ensure Python compatibility.
# %pip install batchgenerators
# %pip install tensorflow_addons
# %pip install SimpleITK

# Commented out IPython magic to ensure Python compatibility.
!python miscnn/data_loading/data_io.py install
!python miscnn/neural_network/model.py install

# %pip install pydicom

from miscnn.processing.subfunctions.abstract_subfunction import Abstract_Subfunction

class ChangeValues(Abstract_Subfunction):
   #---------------------------------------------#
   #                Initialization               #
   #---------------------------------------------#
  def __init__(self, val_to_change, change_in):
    self.val_to_change = val_to_change
    self.change_in = change_in
    #---------------------------------------------#
    #                Preprocessing                #
    #---------------------------------------------#
  def preprocessing(self, sample, training=True):
    seg_temp = sample.seg_data
    if(sample.seg_data is not None):
      sample.seg_data = np.where(seg_temp == self.val_to_change, self.change_in, seg_temp)
    #---------------------------------------------#
    #               Postprocessing                #
    #---------------------------------------------#
  def postprocessing(self, sample, prediction, activation_output=False):
    pred = prediction
    if prediction is not None:
      prediction = np.where(pred == self.change_in, self.val_to_change, pred)
    return prediction

from miscnn.processing.subfunctions import  Normalization, Resize
# Create a pixel value normalization subfunction through Z-Score
sf_normalization = Normalization(mode="z-score")
# Create our pixel value changing subfunction
sf_change = ChangeValues(val_to_change=255, change_in=1)
sf_resize = Resize((512, 512))
subfunc = [sf_resize, sf_change, sf_normalization]

import miscnn

from miscnn.processing.data_augmentation import Data_Augmentation

# Create and configure the Data Augmentation class
data_aug = Data_Augmentation(cycles=6, scaling=True, rotations=True, elastic_deform=True, mirror=True,
                             brightness=True, contrast=True, gamma=True, gaussian_noise=True)

print(len(os.listdir("/content/gdrive/MyDrive/miscnn_data/data_new2/")))

import miscnn
from miscnn.processing.preprocessor import Preprocessor
#from miscnn.neural_network.architecture.unet.standard import Architecture
from miscnn.neural_network.model import Neural_Network
from miscnn.data_loading.data_io import Data_IO
from miscnn.neural_network.architecture.unet.residual import Architecture
from miscnn.neural_network.metrics import tversky_crossentropy, dice_soft, \
                                          dice_crossentropy, tversky_loss

# Create a Data I/O interface for kidney tumor CT scans in NIfTI format
from miscnn.data_loading.interfaces import Image_interface
interface = Image_interface()

# Initialize data path and create the Data I/O instance
data_path = "/content/gdrive/MyDrive/miscnn_data/data_new2/"
#data_path = ''
with tf.device('/gpu:0'):
  data_io = Data_IO(interface, data_path)

# Create a Preprocessor instance to configure how to preprocess the data into batches
pp = Preprocessor(data_io=data_io, data_aug=data_aug,
                            batch_size=12, subfunctions=subfunc,
                            prepare_subfunctions=True, prepare_batches=False,
                            analysis="fullimage")

# Create a deep learning neural network model with a standard U-Net architecture

unet_residual = Architecture(activation="softmax")
model = Neural_Network(learning_rate=0.00001, loss=tversky_crossentropy, metrics= dice_soft, preprocessor=pp, architecture=unet_residual)

from batchgenerators.augmentations.utils import resize_segmentation
from batchgenerators.augmentations.spatial_transformations import augment_resize
import sklearn.model_selection
from miscnn.evaluation import split_validation, cross_validation
from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard

# Create sample list
sample_list = data_io.get_indiceslist()
sample_list.sort()
sample_list = sample_list[1:]
print((sample_list))

# Create train and test name lists
data_train, data_test = sklearn.model_selection.train_test_split(sample_list, test_size=0.3)

data_train.sort()
data_test.sort()

# train using split_validation to monitor validation metrics and change lr if loss does not decrease during 'patience' number of epochs

# Define callback reduce learning rate on plateau
cb_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1,
                          mode='min', min_delta=0.00001, cooldown=1,
                          min_lr=0.00001)
# Define callback early stopping
cb_es = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1,
                      mode='min')
with tf.device('/gpu:0'):
  split_validation(data_train, model, epochs=30, iterations=6, callbacks=[cb_lr, cb_es])

# Predict the segmentation for test samples
pred = model.predict(data_test, return_output=True)

from IPython.display import display

# Load the first sample via MIScnn data loader
model.predict(data_test[1])
sample_test = data_io.sample_loader(data_test[1], load_seg=True, load_pred=True)

# Visualize the ground truth segmentation
seg_data = sample_test.seg_data * 100
print("Shape of segmentation:", seg_data.shape)
seg = Image.fromarray(np.reshape(seg_data, seg_data.shape[:-1]))
display(seg)

# Visualize the predicted segmentation
pred_data = sample_test.pred_data * 100
print("Shape of prediction:", pred_data.shape)
pred = Image.fromarray(np.reshape(pred_data, pred_data.shape[:-1]))
display(pred)